{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dlc_practical_prologue import generate_pair_sets\n",
    "import torch.nn as nn\n",
    "from print_util import *\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate raw data, process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_device(n, device='cpu'):\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = generate_pair_sets(n)\n",
    "    train_input = train_input.to(device=device)\n",
    "    train_target = train_target.to(device=device)\n",
    "    train_classes = train_classes.to(device=device)\n",
    "    test_input = test_input.to(device=device)\n",
    "    test_target = test_target.to(device=device)\n",
    "    test_classes = test_classes.to(device=device)\n",
    "    return train_input, train_target, train_classes, test_input, test_target, test_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = generate_data_device(1000, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(tensor):\n",
    "    mu, std = tensor.mean(), tensor.std()\n",
    "    tmp = tensor.sub(mu).div(std)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot_labels(target):\n",
    "    tmp = target.new_zeros(target.size(0), target.max() + 1)\n",
    "    tmp.scatter_(1, target.view(-1, 1), 1.0)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We normalized the data so it has mean 0 and std 1._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = normalize_data(train_input)\n",
    "test_input = normalize_data(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set mean = 7.753956055012168e-08\n",
      "Training set std = 1.0\n",
      "\n",
      "Test set mean = -3.269740478373251e-09\n",
      "Test set std = 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set mean = {a}\".format(a = train_input.mean().item()))\n",
    "print(\"Training set std = {s}\\n\".format(s = train_input.std().item()))\n",
    "print(\"Test set mean = {a}\".format(a = test_input.mean().item()))\n",
    "print(\"Test set std = {s}\".format(s = test_input.std().item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We will create a validation set to tune hyperparameters. This validation set is created from the training set in order to have fully independent testing data._\n",
    "\n",
    "_80% of the training data goes to training and the remaining 20% for our validation set._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_permutation = torch.randperm(train_input.size(0))\n",
    "\n",
    "validation_proportion = 0.2\n",
    "split = int(0.2 * train_input.size(0))\n",
    "\n",
    "validation_index = index_permutation[:split]\n",
    "training_index = index_permutation[split:]\n",
    "\n",
    "validation_input = train_input[validation_index]\n",
    "validation_target = train_target[validation_index]\n",
    "validation_classes = train_classes[validation_index]\n",
    "\n",
    "train_input = train_input[training_index]\n",
    "train_target = train_target[training_index]\n",
    "train_classes = train_classes[training_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "print(train_input.size(0))\n",
    "print(validation_input.size(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating & Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_input, test_target, test_classes, model, criterion, batch_size):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        nb_data_errors = 0\n",
    "        loss_sum = 0\n",
    "        \n",
    "        for inputs, targets in zip(test_input.split(batch_size),\n",
    "                                  test_target.split(batch_size)):\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss_sum += loss\n",
    "            _, predicted_classes = torch.max(outputs, 1)\n",
    "            \n",
    "            for k in range(len(inputs)):\n",
    "                if targets[k] != predicted_classes[k]:\n",
    "                    nb_data_errors = nb_data_errors + 1\n",
    "\n",
    "        accuracy = (1 - (nb_data_errors / test_input.size(0))) * 100\n",
    "        \n",
    "        return accuracy, loss_sum.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, train_classes, test_input, test_target, test_classes, nb_epoch, batch_size, optimizer_params, logging = False):\n",
    "    \n",
    "    nb_epoch, batch_size = nb_epoch, batch_size\n",
    "    lr, momentum, weight_decay, gamma = optimizer_params['lr'], optimizer_params['momentum'], optimizer_params['weight_decay'], optimizer_params['gamma']    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    if logging:\n",
    "        log_acc_loss_header(color=Color.GREEN)\n",
    "    \n",
    "        train_accuracies = []\n",
    "        train_losses = []\n",
    "        test_accuracies = []\n",
    "        test_losses = []\n",
    "        start_time = time.time()\n",
    "    \n",
    "    for e in range(nb_epoch):\n",
    "        for inputs, targets in zip(train_input.split(batch_size),\n",
    "                                  train_target.split(batch_size)):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()  # Update the learning rate\n",
    "        \n",
    "        if logging:    \n",
    "            train_acc, train_loss = test(train_input, train_target, train_classes, model, criterion, batch_size)\n",
    "            test_acc, test_loss = test(test_input, test_target, test_classes, model, criterion, batch_size)\n",
    "        \n",
    "            train_accuracies.append(train_acc)\n",
    "            train_losses.append(train_loss)\n",
    "            test_accuracies.append(test_acc)\n",
    "            test_losses.append(test_loss)\n",
    "        \n",
    "            elapsed_time = time.time() - start_time\n",
    "            log_acc_loss(e, nb_epoch, elapsed_time, train_loss, train_acc, test_loss, test_acc, persistent=False)\n",
    "            \n",
    "    if logging:\n",
    "        print()\n",
    "        return train_accuracies, train_losses, test_accuracies, test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Testing if the training is done correctly._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch       Time    Train loss     Train accuracy      Test loss      Test accuracy       \u001b[0m\n",
      "[20/20]     15s     0.1243         100.0000            11.9015        80.1000             \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "basic_model = models.BaselineNetwork()\n",
    "basic_model = basic_model.to(device=device)\n",
    "\n",
    "train_accuracies, train_losses, test_accuracies, test_losses = train_model(basic_model,\n",
    "                                                                           train_input, \n",
    "                                                                           train_target, \n",
    "                                                                           train_classes, \n",
    "                                                                           test_input, \n",
    "                                                                           test_target, \n",
    "                                                                           test_classes, \n",
    "                                                                           20, \n",
    "                                                                           BATCH_SIZE, \n",
    "                                                                           {'lr': 0.1, 'momentum':0.9, 'weight_decay': 0.0, 'gamma': 0.8}, \n",
    "                                                                           logging = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We will now tune hyperparameters. For now, we are tuning the learning rate, the momemtum and the number of epochs._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "momentums = [0.9] #[0.5, 0.7, 0.9]\n",
    "nb_epochs = [20]#, 50, 100] #, 100]\n",
    "weight_decays = [0.0, 0.01, 0.1]\n",
    "gamma = 0.8\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for momentum in momentums:\n",
    "        for nb_epoch in nb_epochs:\n",
    "            for weight_decay in weight_decays:\n",
    "            \n",
    "                # creating params for optimizer\n",
    "                optimizer_params = {'lr':lr, 'momentum':momentum, 'weight_decay': weight_decay, 'gamma': gamma}\n",
    "                \n",
    "                # initialize raw model\n",
    "                model = models.BaselineNetwork()\n",
    "                model = model.to(device=device)\n",
    "                \n",
    "                # train model on training data\n",
    "                train_model(model,\n",
    "                            train_input,\n",
    "                            train_target,\n",
    "                            train_classes,\n",
    "                            None,\n",
    "                            None,\n",
    "                            None,\n",
    "                            nb_epoch, BATCH_SIZE, optimizer_params)\n",
    "                \n",
    "                # compute accuracy on validation data\n",
    "                accuracy, loss = test(validation_input, validation_target, validation_classes, model, nn.CrossEntropyLoss(), BATCH_SIZE)\n",
    "                \n",
    "                if accuracy > best_accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    best_params['lr'] = lr\n",
    "                    best_params['momentum'] = momentum\n",
    "                    best_params['nb_epoch'] = nb_epoch\n",
    "                    best_params['weight_decay'] = weight_decay\n",
    "                    \n",
    "print(\"Best accuracy obtained = {a}\\n\".format(a = best_accuracy))\n",
    "print(\"with the following hyperparameters:\\n\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: Hyperparameters tuning is not optimal yet, do not consider the above results as  good yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_optimizer_params = {'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0, 'gamma': 0.8}\n",
    "best_nb_epoch = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Now that we have the best hyperparameters let's retrained the model and visualize the evolution of accuracy and loss on both the train and test sets._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc_loss(train_accuracies, train_losses, test_accuracies, test_losses):\n",
    "    n = len(train_accuracies)\n",
    "    major_ticks = list(range(0, n, 10))\n",
    "    minor_ticks = list(range(0, n, 1))\n",
    "    \n",
    "    fig, axs = plt.subplots(2, dpi=240, figsize=(15, 12))\n",
    "    axs[0].plot(train_accuracies, color='Blue')\n",
    "    axs[0].plot(test_accuracies, color='Red')\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set(xlabel='Training epochs', ylabel='Accuracy (%)')\n",
    "    axs[0].grid()\n",
    "    axs[0].legend(['Train set', 'Test set'])\n",
    "    axs[0].set_xlim(left=0)\n",
    "    axs[0].set_xlim(right=n-1)\n",
    "    axs[0].set_xticks(major_ticks)\n",
    "    axs[0].set_xticks(minor_ticks, minor=True)\n",
    "    axs[0].grid(which='minor', alpha=0.3)\n",
    "    axs[0].grid(which='major', alpha=0.7)\n",
    "    \n",
    "    axs[1].plot(train_losses, color='Blue')\n",
    "    axs[1].plot(test_losses, color='Red')\n",
    "    axs[1].set_title(\"Cross-Entropy Loss\")\n",
    "    axs[1].set(xlabel='Training epochs', ylabel='Loss')\n",
    "    axs[1].grid()\n",
    "    axs[1].legend(['Train set', 'Test set'])\n",
    "    axs[1].set_xticks(major_ticks)\n",
    "    axs[1].set_xticks(minor_ticks, minor=True)\n",
    "    axs[1].grid(which='minor', alpha=0.3)\n",
    "    axs[1].grid(which='major', alpha=0.7)\n",
    "    axs[1].set_xlim(left=0)\n",
    "    axs[1].set_xlim(right=n-1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = models.BaselineNetwork()\n",
    "final_model = final_model.to(device)\n",
    "# We regenerate data to train the model on all the training data available. \n",
    "# We don't need the validation split at this step.\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = generate_data_device(1000, device=device)\n",
    "train_input = normalize_data(train_input)\n",
    "test_input = normalize_data(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies, train_losses, test_accuracies, test_losses = train_model(final_model,\n",
    "                                                                           train_input, \n",
    "                                                                           train_target, \n",
    "                                                                           train_classes, \n",
    "                                                                           test_input, \n",
    "                                                                           test_target, \n",
    "                                                                           test_classes, \n",
    "                                                                           best_nb_epoch, \n",
    "                                                                           BATCH_SIZE, \n",
    "                                                                           best_optimizer_params, \n",
    "                                                                           logging = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_loss(train_accuracies, train_losses, test_accuracies, test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_In order to test the model we will generate new data (training and test set), retrained the model on the new data en evaluate it on the new test set. We will do this process more than 10 times and estimates the mean accuracy as well as its standard deviation._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_rounds = 10\n",
    "test_model = models.BaselineNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, nb_rounds, criterion):\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    for round in range(nb_rounds):\n",
    "        \n",
    "        # initialize new model\n",
    "        model_evaluated = model().to(device)\n",
    "        # generate new data\n",
    "        train_input, train_target, train_classes, test_input, test_target, test_classes = generate_data_device(1000, device=device)\n",
    "        train_input = normalize_data(train_input)\n",
    "        test_input = normalize_data(test_input)\n",
    "        \n",
    "        train_model(model_evaluated,\n",
    "                    train_input,\n",
    "                    train_target,\n",
    "                    train_classes,\n",
    "                    None,\n",
    "                    None,\n",
    "                    None,\n",
    "                    best_nb_epoch, BATCH_SIZE, best_optimizer_params)\n",
    "        \n",
    "        accuracy, loss = test(test_input, test_target, test_classes, model_evaluated, criterion, BATCH_SIZE)\n",
    "        \n",
    "        print(\"Round {i}: accuracy = {a:0.2f}% | loss = {l:0.4f}\".format(i = (round + 1), a = accuracy, l = loss))\n",
    "        \n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "    return torch.FloatTensor(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = evaluate_model(test_model, nb_rounds, nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The mean accuracy is: {a:0.2f}\".format(a = accuracies.mean()))\n",
    "print(\"The accuracy std is: {s:0.4f}\".format(s = accuracies.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
